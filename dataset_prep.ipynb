{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = Path(\n",
    "    r\"F:\\Dropbox (Personal)\\BCII\\BCI Challenges\\2024 ALVI EMG Decoding\\dataset_v2_blocks\\dataset_v2_blocks\"\n",
    ")\n",
    "\n",
    "dest_folder = Path(\n",
    "    r'F:\\Dropbox (Personal)\\BCII\\BCI Challenges\\2024 ALVI EMG Decoding\\kaggle_files'\n",
    ")\n",
    "\n",
    "hand_types = [\"left\", \"right\"]\n",
    "human_types = ['health', 'amputant']\n",
    "\n",
    "\n",
    "\n",
    "LEFT_TO_RIGHT_HAND = [6, 5, 4, 3, 2, 1, 0, 7]\n",
    "N_MYO = 8\n",
    "N_ANGLES = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_human_types = {ht:0 for ht in human_types}\n",
    "\n",
    "for ht in human_types:\n",
    "    by_hand_types = {hand_type:0 for hand_type in hand_types}\n",
    "    for hand_type in hand_types:\n",
    "        base_folder = data_folder / ht / hand_type\n",
    "\n",
    "        # get all folders \n",
    "        folders = glob.glob(str(base_folder / \"*\"))\n",
    "        by_hand_types[hand_type] = len(folders)\n",
    "        by_human_types[ht] += len(folders)\n",
    "\n",
    "    print(f\"{ht}: {by_hand_types}\")\n",
    "print(f\"Total: {by_human_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "For each \"human type\" and \"hand type\", get all .npz files in the `train` and `test` folders.\n",
    "Creates one huge dataframe with all the EMG data and target angles. Each row is one sample and has some metadata to identify it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_data(data:dict, folder:str, name:str, tset:str,  human_type:str, hand_type:str):\n",
    "    \"\"\"\n",
    "        Loads all .npz files in a folder and adds the data to a growin dict\n",
    "        storing metadata, features and variables being predicted.\n",
    "    \"\"\"\n",
    "    files = glob.glob(str(folder / \"*.npz\"))\n",
    "    print(f\"{human_type}/{hand_type}/{name}/{tset}: {len(files)} files\")\n",
    "\n",
    "    for tid, fl in enumerate(files):\n",
    "        fdata = dict(np.load(fl))\n",
    "\n",
    "        T = fdata['data_myo'].shape[0]\n",
    "\n",
    "        ht = \"healty\" if human_type == \"health\" else \"amputee\"\n",
    "        data['subject_type'] += [ht] * T\n",
    "        data['subject_name'] += [name.split(\"_\")[0]] * T\n",
    "        data['exp_id'] += [name] * T\n",
    "        data['trial_id'] += [tid] * T\n",
    "        data['condition'] += [ht] * T\n",
    "\n",
    "        for i in range(N_ANGLES):\n",
    "            data[f\"ang_{i}\"] += fdata[f\"data_angles\"][:, i].tolist()\n",
    "\n",
    "\n",
    "        if hand_type == 'left':\n",
    "            emg_data = fdata['data_myo'][:, LEFT_TO_RIGHT_HAND]\n",
    "        else:\n",
    "            emg_data = fdata['data_myo']\n",
    "\n",
    "        for i in range(N_MYO):\n",
    "            data[f\"myo_{i}\"] += emg_data[:, i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'subject_type': [],\n",
    "    'subject_name': [],\n",
    "    'exp_id': [],\n",
    "    'trial_id': [],\n",
    "    'condition': [],\n",
    "}\n",
    "data = {**data, **{f\"ang_{i}\": [] for i in range(N_ANGLES)}}\n",
    "data = {**data, **{f\"myo_{i}\": [] for i in range(N_MYO)}}\n",
    "\n",
    "\n",
    "\n",
    "for ht in human_types:\n",
    "    for hand_type in hand_types:\n",
    "        base_folder = data_folder / ht / hand_type\n",
    "\n",
    "        # get all folders \n",
    "        folders = glob.glob(str(base_folder / \"*\"))\n",
    "        \n",
    "        for folder in folders:\n",
    "            name = Path(folder).name\n",
    "\n",
    "            for tset in (\"train\", \"test\"):\n",
    "                # find all numpy files in folder/train\n",
    "                complete_folder = Path(folder) / \"preproc_angles\" / tset\n",
    "                if not complete_folder.exists():\n",
    "                    continue\n",
    "                \n",
    "                # add all data to original dict\n",
    "                add_to_data(\n",
    "                    data, complete_folder, name, tset, ht, hand_type\n",
    "                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "del data\n",
    "\n",
    "# add a unique ID column \n",
    "df['sample_id'] = np.arange(df.shape[0])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split TRAIN vs TEST\n",
    "\n",
    "TEST is made of only data from fedya, 1/2 of the data from this subject is included in the training data, the remainder is kept for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a subset of fedya's trials\n",
    "fedya = df.loc[df.subject_name == \"fedya\"]\n",
    "fedya_trials = fedya.trial_id.unique()\n",
    "fedya_trials_test = fedya_trials[::2]\n",
    "fedya_trials_train = fedya_trials[1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep samples when subject != 'fedya' or for fedya trial_id is not in trials_test\n",
    "train = df.loc[(df.subject_name != \"fedya\") | (df.trial_id.isin(fedya_trials_train))]\n",
    "test_data = df.loc[(df.subject_name == \"fedya\") & (df.trial_id.isin(fedya_trials_test))]\n",
    "\n",
    "print(train.shape)\n",
    "print(test_data.shape)\n",
    "print(train.tail(5))\n",
    "print(test_data.tail(5))\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [f'ang_{i}' for i in range(N_ANGLES)]\n",
    "inputs_cols = [f'myo_{i}' for i in range(N_MYO)]\n",
    "\n",
    "# select columsn subsets\n",
    "solution = test_data[['sample_id'] + target_cols]\n",
    "print(solution.head())\n",
    "\n",
    "test = test_data[['sample_id', 'trial_id'] + inputs_cols]\n",
    "print(test.head())\n",
    "\n",
    "# make a sample solution df\n",
    "sample_solution = solution.copy()\n",
    "sample_solution[target_cols] = 0.0\n",
    "print(sample_solution.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an `Usage` column to solution to split between public and private leaderboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test.shape[0] == solution.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = list(test.trial_id.unique())\n",
    "public = trials[::2]\n",
    "\n",
    "\n",
    "usage = np.zeros(solution.shape[0])\n",
    "\n",
    "for tr in trials:\n",
    "    trial_usage = 1 if tr in public else 0\n",
    "    rows_idxs = np.where(test.trial_id == tr)\n",
    "    usage[rows_idxs] = trial_usage\n",
    "\n",
    "\n",
    "usage = ['Public' if u == 1 else 'Private' for u in usage]\n",
    "solution['Usage'] = usage\n",
    "solution.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(dest_folder / 'train.csv', index=False)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(dest_folder / 'test.csv', index=False)\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv(dest_folder / 'solution.csv', index=False)\n",
    "print(solution.shape)\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution.to_csv(dest_folder / 'sample_solution.csv', index=False)\n",
    "print(sample_solution.shape)\n",
    "sample_solution.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
